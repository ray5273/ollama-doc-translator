#!/usr/bin/env python3
"""
ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš© ë²ˆì—­ ìŠ¤í¬ë¦½íŠ¸
Ollama APIë¥¼ ì‚¬ìš©í•˜ì—¬ docs/ í´ë”ì˜ í•œêµ­ì–´ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì„ docs-en/ í´ë”ë¡œ ë²ˆì—­í•©ë‹ˆë‹¤.
"""

import os
import json
import requests
import time
from pathlib import Path

def check_ollama_server(ssl_verify=True):
    """Ollama ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸"""
    try:
        response = requests.get("http://localhost:11434/api/tags", timeout=5, verify=ssl_verify)
        return response.status_code == 200
    except:
        return False

def check_model_available(model="exaone3.5:7.8b", ssl_verify=True):
    """ì§€ì •ëœ ëª¨ë¸ì´ ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸"""
    try:
        response = requests.get("http://localhost:11434/api/tags", timeout=5, verify=ssl_verify)
        if response.status_code == 200:
            models = response.json()
            model_names = [m['name'] for m in models.get('models', [])]
            return model in model_names
        return False
    except:
        return False

def translate_with_ollama(text, model="exaone3.5:7.8b", ssl_verify=True):
    """Ollama APIë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ë²ˆì—­"""
    url = "http://localhost:11434/api/generate"
    
    prompt = f"""ë‹¤ìŒ í•œêµ­ì–´ í…ìŠ¤íŠ¸ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”. ë§ˆí¬ë‹¤ìš´ í˜•ì‹ê³¼ êµ¬ì¡°ë¥¼ ìœ ì§€í•˜ì„¸ìš”. ë²ˆì—­ëœ í…ìŠ¤íŠ¸ë§Œ ë°˜í™˜í•˜ê³  ì¶”ê°€ì ì¸ ì„¤ëª…ì€ í•˜ì§€ ë§ˆì„¸ìš”.

í•œêµ­ì–´ í…ìŠ¤íŠ¸:
{text}

ì˜ì–´ ë²ˆì—­:"""
    
    payload = {
        "model": model,
        "prompt": prompt,
        "stream": False,
        "options": {
            "temperature": 0.3,
            "top_p": 0.9
        }
    }
    
    try:
        print(f"ë²ˆì—­ ì¤‘... (ëª¨ë¸: {model})")
        response = requests.post(url, json=payload, timeout=300, verify=ssl_verify)
        response.raise_for_status()
        result = response.json()
        translated = result.get('response', '').strip()
        
        # ê°€ë” ëª¨ë¸ì´ ì¶”ê°€ ì„¤ëª…ì„ í¬í•¨í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì •ë¦¬
        if translated.startswith('ì˜ì–´ ë²ˆì—­:'):
            translated = translated.replace('ì˜ì–´ ë²ˆì—­:', '').strip()
        
        return translated
    except Exception as e:
        print(f"ë²ˆì—­ ì˜¤ë¥˜: {e}")
        return text

def process_markdown_file(input_path, output_path, context_length=4096, ssl_verify=True):
    """ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì„ ë²ˆì—­í•˜ì—¬ ì €ì¥"""
    print(f"\në²ˆì—­ ì¤‘: {input_path} -> {output_path}")
    
    with open(input_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    if context_length > 0:
        # Calculate safe input length (reserve space for prompt and output)
        prompt_overhead = 500  # Space for translation prompt
        output_reserve = context_length // 3  # Reserve 1/3 for output
        safe_input_length = context_length - prompt_overhead - output_reserve
        
        if len(content) > safe_input_length:
            # Split content into chunks based on safe input length
            chunks = []
            current_chunk = ""
            paragraphs = content.split('\n\n')
            
            for paragraph in paragraphs:
                if len(current_chunk) + len(paragraph) + 2 <= safe_input_length:
                    if current_chunk:
                        current_chunk += '\n\n' + paragraph
                    else:
                        current_chunk = paragraph
                else:
                    if current_chunk:
                        chunks.append(current_chunk)
                    current_chunk = paragraph
            
            if current_chunk:
                chunks.append(current_chunk)
            
            translated_chunks = []
            
            print(f"ì²­í¬ë¡œ ë¶„í• í•˜ì—¬ ë²ˆì—­ ({len(chunks)}ê°œ ì²­í¬, ì•ˆì „í•œ ì…ë ¥ ê¸¸ì´: {safe_input_length})")
            
            for i, chunk in enumerate(chunks):
                print(f"ì²­í¬ ë²ˆì—­ ì¤‘ {i+1}/{len(chunks)}")
                translated_chunk = translate_with_ollama(chunk, ssl_verify=ssl_verify)
                translated_chunks.append(translated_chunk)
                time.sleep(1)  # API ì†ë„ ì œí•œ
            
            translated_content = '\n\n'.join(translated_chunks)
        else:
            # íŒŒì¼ì´ ì¶©ë¶„íˆ ì‘ì•„ì„œ í•œ ë²ˆì— ì²˜ë¦¬ ê°€ëŠ¥
            print(f"ì „ì²´ íŒŒì¼ì„ í•œ ë²ˆì— ë²ˆì—­í•©ë‹ˆë‹¤ (í¬ê¸°: {len(content)}, ì•ˆì „ ì œí•œ: {safe_input_length})...")
            translated_content = translate_with_ollama(content, ssl_verify=ssl_verify)
    else:
        # Context length ì œí•œ ì—†ìŒ, ì „ì²´ íŒŒì¼ì„ í•œ ë²ˆì— ì²˜ë¦¬
        print("ì „ì²´ íŒŒì¼ì„ í•œ ë²ˆì— ë²ˆì—­í•©ë‹ˆë‹¤ (context ì œí•œ ì—†ìŒ)...")
        translated_content = translate_with_ollama(content, ssl_verify=ssl_verify)
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    # ë²ˆì—­ëœ ë‚´ìš© ì €ì¥
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(translated_content)
    
    print(f"ë²ˆì—­ ì™„ë£Œ: {output_path}")

def main():
    print("=== Ollama ë¬¸ì„œ ë²ˆì—­ê¸° ===")
    
    # ì„¤ì • ì˜µì…˜
    ssl_verify = input("SSL ì¸ì¦ì„œ ê²€ì¦ì„ ì‚¬ìš©í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n, ê¸°ë³¸ê°’: y): ").lower() not in ['n', 'no']
    context_input = input("ëª¨ë¸ context ê¸¸ì´ë¥¼ ì…ë ¥í•˜ì„¸ìš” (0 = chunking ì•ˆí•¨, ê¸°ë³¸ê°’: 4096): ").strip()
    context_length = int(context_input) if context_input else 4096
    
    print(f"ì„¤ì •: SSL ê²€ì¦ = {ssl_verify}, Context ê¸¸ì´ = {context_length}")
    
    # Ollama ì„œë²„ í™•ì¸
    if not check_ollama_server(ssl_verify):
        print("âŒ Ollama ì„œë²„ê°€ ì‹¤í–‰ë˜ê³  ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
        print("ë‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ Ollamaë¥¼ ì‹œì‘í•˜ì„¸ìš”: ollama serve")
        return
    
    print("âœ… Ollama ì„œë²„ ì—°ê²°ë¨")
    
    # ëª¨ë¸ í™•ì¸
    model = "exaone3.5:7.8b"
    if not check_model_available(model, ssl_verify):
        print(f"âŒ ëª¨ë¸ '{model}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print(f"ë‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”: ollama pull {model}")
        return
    
    print(f"âœ… ëª¨ë¸ '{model}' ì‚¬ìš© ê°€ëŠ¥")
    
    docs_dir = Path('docs')
    docs_en_dir = Path('docs-en')
    
    if not docs_dir.exists():
        print("âŒ docs/ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # docs/ ë””ë ‰í† ë¦¬ì—ì„œ ëª¨ë“  ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì°¾ê¸°
    md_files = list(docs_dir.rglob('*.md'))
    
    if not md_files:
        print("âŒ docs/ ë””ë ‰í† ë¦¬ì— ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"\nğŸ“„ {len(md_files)}ê°œì˜ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤:")
    for md_file in md_files:
        print(f"  - {md_file}")
    
    print(f"\nğŸš€ ë²ˆì—­ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    
    for md_file in md_files:
        # ìƒëŒ€ ê²½ë¡œ ê³„ì‚°
        rel_path = md_file.relative_to(docs_dir)
        output_file = docs_en_dir / rel_path
        
        # ì´ë¯¸ ì¡´ì¬í•˜ê³  ë” ìƒˆë¡œìš´ ê²½ìš° ê±´ë„ˆë›°ê¸°
        if output_file.exists() and output_file.stat().st_mtime > md_file.stat().st_mtime:
            print(f"â­ï¸  {md_file} ê±´ë„ˆë›°ê¸° (ë²ˆì—­ë³¸ì´ ìµœì‹ )")
            continue
        
        process_markdown_file(md_file, output_file, context_length, ssl_verify)
    
    print(f"\nğŸ‰ ëª¨ë“  ë²ˆì—­ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    print(f"ë²ˆì—­ëœ íŒŒì¼ë“¤ì€ '{docs_en_dir}' ë””ë ‰í† ë¦¬ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()