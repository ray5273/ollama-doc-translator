# Problem Solving Guide

This guide provides solutions to common issues encountered while translating Ollama documents.

## Common Issues

### 1. Ollama Server Connection Error

#### Symptoms
```
âŒ Error: Ollama ì„œë²„ê°€ ì‹¤í–‰ë˜ê³  ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.
âŒ Connection refused: http://localhost:11434
```

#### Troubleshooting Steps

1. **Check Ollama Server Status**:
   ```bash
   # Check process
   ps aux | grep ollama
   
   # Check service status (Linux)
   systemctl status ollama
   ```

2. **Start Ollama Server**:
   ```bash
   # Run in background
   ollama serve &
   
   # Or run in foreground
   ollama serve
   ```

3. **Port Verification**:
   ```bash
   # Check if port 11434 is in use
   netstat -tulpn | grep 11434
   lsof -i :11434
   ```

4. **Firewall Configuration**:
   ```bash
   # Ubuntu/Debian
   sudo ufw allow 11434
   
   # CentOS/RHEL
   sudo firewall-cmd --add-port=11434/tcp --permanent
   sudo firewall-cmd --reload
   ```

### 2. Model Download Failure

#### Symptoms
```
âŒ ëª¨ë¸ 'exaone3.5:7.8b'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
âŒ Failed to pull model: network timeout
```

#### Troubleshooting Steps

1. **Check Internet Connection**:
   ```bash
   curl -I https://ollama.com
   ```

2. **ìˆ˜ë™ìœ¼ë¡œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ**:
   ```bash
   # ëª¨ë¸ ê°•ì œ ì¬ë‹¤ìš´ë¡œë“œ
   ollama rm exaone3.5:7.8b
   ollama pull exaone3.5:7.8b
   ```

3. **í”„ë¡ì‹œ ì„¤ì •** (íšŒì‚¬ ë„¤íŠ¸ì›Œí¬):
   ```bash
   export HTTP_PROXY=http://proxy.company.com:8080
   export HTTPS_PROXY=http://proxy.company.com:8080
   ollama pull exaone3.5:7.8b
   ```

4. **ë””ìŠ¤í¬ ê³µê°„ í™•ì¸**:
   ```bash
   df -h ~/.ollama/models
   ```

### 3. GitHub Actions ì›Œí¬í”Œë¡œìš° ì‹¤íŒ¨

#### ì¦ìƒ
```
âŒ Action failed: Container failed to start
âŒ Permission denied
```

#### Troubleshooting Steps

1. **Self-hosted Runner Check**:
   ```bash
   # Check Runner status
   ./run.sh --check
   
   # Restart Runner
   ./run.sh
   ```

2. **Docker Permission Issues** (Linux):
   ```bash
   # Add user to docker group
   sudo usermod -aG docker $USER
   
   # Re-login required
   newgrp docker
   ```

3. **Token Permissions Verification**:
   - Repository Settings â†’ Actions â†’ General
   - Select "Read and write permissions" under "Workflow permissions"

### 4. Translation Quality Issues

#### Symptoms
- Inaccurate or inconsistent translations
- Markdown formatting issues
- Incorrect translation of technical terms

#### Solutions

1. **Temperature Adjustment**:
   ```yaml
   temperature: 0.1  # For more consistent translations
   ```

2. **Use a Larger Model**:
   ```yaml
   model: 'exaone3.5:32b'  # For more accurate translations
   ```

3. **Adjust Chunk Size**:
   ```python
   # Modify in entrypoint.py
   chunks = content.split('\n\n')  # Split by paragraphs
   # Alternatively
   chunks = content.split('\n')    # Split by lines
   ```

4. **Improve Prompt**:
   ```python
   prompt = f"""Translate the following Korean technical document into English. 
   Ensure accurate preservation of Markdown formatting and technical terms.
   
   Korean Text:
   {text}
   
   English Translation:"""
   ```

### 5. Memory Insufficient Error

#### Symptoms
```
âŒ Out of memory error
âŒ Model failed to load
```

#### Solutions

1. **Check System Memory**:
   ```bash
   free -h
   htop
   ```

2. **ë” ì‘ì€ ëª¨ë¸ ì‚¬ìš©**:
   ```yaml
   model: 'mistral:7b'  # ë” ì ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©
   ```

3. **ìŠ¤ì™‘ ë©”ëª¨ë¦¬ ì¶”ê°€** (Linux):
   ```bash
   # 4GB ìŠ¤ì™‘ íŒŒì¼ ìƒì„±
   sudo fallocate -l 4G /swapfile
   sudo chmod 600 /swapfile
   sudo mkswap /swapfile
   sudo swapon /swapfile
   ```

4. **Docker ë©”ëª¨ë¦¬ ì œí•œ**:
   ```yaml
   # docker-compose.yml
   services:
     ollama:
       deploy:
         resources:
           limits:
             memory: 8G
   ```

### 6. Pull Request ìƒì„± ì‹¤íŒ¨

#### ì¦ìƒ
```
âŒ Failed to create pull request
âŒ GitHub CLI not found
```

#### Solutions

1. **Install GitHub CLI**:
   ```bash
   # Ubuntu/Debian
   sudo apt install gh
   
   # macOS
   brew install gh
   
   # Windows
   winget install GitHub.cli
   ```

2. **Set Up Authentication**:
   ```bash
   gh auth login
   ```

3. **Verify Token Permissions**:
   - Check repository permissions under Personal access tokens

4. **Disable Manual PR Creation**:
   ```yaml
   create-pr: false
   ```

### 7. File Encoding Issues

#### Symptoms
```
âŒ UnicodeDecodeError
âŒ í•œê¸€ì´ ê¹¨ì ¸ì„œ í‘œì‹œë¨
```

#### Solution Steps

1. **Check File Encoding**:
   ```bash
   file -i docs/*.md
   ```

2. **Convert to UTF-8**:
   ```bash
   # Convert file to UTF-8 encoding
   iconv -f EUC-KR -t UTF-8 input.md > output.md
   ```

3. **Remove BOM (if necessary)**:
   ```bash
   sed -i '1s/^\xEF\xBB\xBF//' *.md
   ```

## Performance Optimization Tips

### 1. Improve Translation Speed

```yaml
# ë³‘ë ¬ ì²˜ë¦¬ í™œì„±í™”
max-parallel: 3

# ê¸°ì¡´ íŒŒì¼ ìŠ¤í‚µ
skip-existing: true

# ë” ë¹ ë¥¸ ëª¨ë¸ ì‚¬ìš©
model: 'mistral:7b'
```

### 2. Resource Monitoring

```bash
# ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§
htop
iostat -x 1
nvidia-smi  # GPU ì‚¬ìš© ì‹œ
```

### 3. Adjust Log Levels

```yaml
# ë””ë²„ê·¸ ëª¨ë“œ ë¹„í™œì„±í™” (í”„ë¡œë•ì…˜)
debug: false
verbose: false
```

## Debugging Tools

### 1. Log Collection

```bash
# Ollama ë¡œê·¸ í™•ì¸
journalctl -u ollama -f

# Docker ë¡œê·¸
docker logs ollama-container

# GitHub Actions ë¡œê·¸ ë‹¤ìš´ë¡œë“œ
gh run download <run-id>
```

### 2. Direct API Testing

```bash
# Ollama API ì§ì ‘ í˜¸ì¶œ
curl -X POST http://localhost:11434/api/generate \
  -H "Content-Type: application/json" \
  -d '{
    "model": "exaone3.5:7.8b",
    "prompt": "ì•ˆë…•í•˜ì„¸ìš”ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­í•˜ì„¸ìš”",
    "stream": false
  }'
```

### 3. Network Diagnostics

```bash
# ë„¤íŠ¸ì›Œí¬ ì—°ê²° í…ŒìŠ¤íŠ¸
telnet localhost 11434

# DNS í•´ìƒë„ í™•ì¸
nslookup ollama.com
```

## Submit a Support Request

If the issue is not resolved:

1. **Fill out the Issue Template**:
   - Operating System and Version
   - Ollama Version
   - Used Model
   - Error Message
   - Reproduction Steps

2. **Attach Logs**:
   ```bash
   # Collect relevant logs
   ollama serve > ollama.log 2>&1
   ```

3. **GitHub Issues**:
   - [https://github.com/your-username/ollama-doc-translator/issues](https://github.com/your-username/ollama-doc-translator/issues)

4. **Community Forums**:
   - [Ollama Discord](https://discord.gg/ollama)
   - [GitHub Discussions](https://github.com/your-username/ollama-doc-translator/discussions)

## Smart Chunking & Debugging Issues

### 8. Large Document Processing Issues

#### Symptoms
```
âŒ Context length exceeded
âŒ ì²­í¬ê°€ ë„ˆë¬´ í¬ê²Œ ìƒì„±ë¨
âŒ ë²ˆì—­ì´ ì¤‘ê°„ì— ëŠì–´ì§
```

#### Solutions

1. **Adjust Context Length**:
   ```yaml
   context-length: 4096    # Set lower than default 32768
   ```

2. **Debug Chunking Analysis Mode**:
   ```yaml
   debug-mode: true
   ```
   
   Generated Files:
   - `debug_chunks/`: Analysis per chunk
   - `debug_originals/`: Original chunks
   - `debug_translations/`: Translated chunks

3. **Check Console Output**:
   ```bash
   ğŸ“¦ Created 15 token-aware chunks:
      Chunk 1: 1,156 tokens (2,845 chars)  # Verify token count
   ```

### 9. Code Block Corruption Issue

#### Symptoms
```markdown
# ì›ë³¸
```python
def hello():
    print("world")
```

# ë²ˆì—­ ê²°ê³¼ (ì˜ëª»ëœ ê²½ìš°)
```

# Translated Result (Incorrect)
```
print("world")
```
print("world")
```

#### Solutions

1. **Check Debug Comparison Files**:
   ```bash
   debug_comparisons/filename_comparison_001.md
   ```

2. **Check Section Chunking**:
   - Ensure code blocks are not split in the middle of chunks
   - Verify chunks are correctly separated based on H1-H3 headings

3. **Enhance Translation Prompts**:
   The current system already includes logic to preserve code blocks:
   ```
   - IMPORTANT: Do NOT add **bold**, *italic*, or any formatting that wasn't in the original text
   - Only translate text content, never modify or add markdown formatting
   ```
```

### 10. Translation Quality Discrepancy Issues

#### Symptoms
```
âŒ ë™ì¼í•œ ìš©ì–´ê°€ ë‹¤ë¥´ê²Œ ë²ˆì—­ë¨
âŒ ë¬¸ì²´ê°€ ì²­í¬ë§ˆë‹¤ ë‹¬ë¼ì§
âŒ ë²ˆí˜¸ ëª©ë¡ì—ì„œ ë²ˆí˜¸ê°€ ì‚¬ë¼ì§
```

#### Solutions

1. **Temperature Adjustment**:
   ```yaml
   temperature: 0.1        # More consistent translation (default: 0.3)
   ```

2. **Increase Retry Attempts**:
   ```yaml
   max-retries: 5         # Default: 3
   ```

3. **Translation Comparison Analysis**:
   ```bash
   # Compare original and translated text
   debug_comparisons/filename_comparison_001.md
   ```

4. **Preservation of Numbered List Verification**:
   The system is designed to preserve the following pattern:
   ```markdown
   # Original
   - 288. Cache Invalidation Scenario
   
   # Translated Result
   - 288. Cache Invalidation Scenario
   ```

### 11. Debug File Usage

#### Understanding Debug File Structure

1. **Chunk Analysis** (`debug_chunks/`):
   ```markdown
   <!-- DEBUG CHUNK 1/15 -->
   <!-- Tokens: 1,156 -->
   <!-- Characters: 2,845 -->
   <!-- Source: docs/api-guide.md -->
   ```

2. **Translation Performance Analysis**:
   ```bash
   ğŸ“Š Translation Performance Summary:
      â±ï¸ Total time: 2m 34s
      ğŸ“„ Files processed: 12
      ğŸ”„ Total chunks: 67
      ğŸ“ˆ Average chunk size: 1,089 tokens
   ```

3. **Identifying Problem Patterns**:
   - Repeated errors in specific chunks
   - Quality degradation in specific token ranges
   - Formatting issues in specific markdown patterns

#### Optimization Tips

1. **Optimal Chunk Size**:
   - 1,000-1,500 tokens: Balanced quality and speed
   - 500-800 tokens: High quality, slower speed
   - 2,000+ tokens: Faster speed, potential quality drop

2. **Utilizing Section-Based Segmentation**:
   - Always split at H1-H2 levels
   - Split at H3 if chunk size exceeds 200 tokens
   - Never split code blocks

## Frequently Asked Questions (FAQ)

### Q: Why is translation so slow? How can I speed it up?
A: Use GPU acceleration, opt for smaller models, or run on a Self-hosted runner.

### Q: How do I keep specific terms untranslated?
A: Add instructions in the prompt, such as "Keep technical terms in the original language."

### Q: Is multi-language translation supported simultaneously?
A: Currently, only Korean-English translation is supported, but you can sequentially process multiple languages using a matrix strategy.

### Q: Does it work with private repositories?
A: Yes, it supports private repositories using a Personal Access Token.

---

> **âš ï¸ ì´ ë¬¸ì„œëŠ” AIë¡œ ë²ˆì—­ëœ ë¬¸ì„œì…ë‹ˆë‹¤.**
>
> **âš ï¸ This document has been translated by AI.**